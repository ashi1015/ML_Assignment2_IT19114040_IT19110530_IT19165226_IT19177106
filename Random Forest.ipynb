{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85300d266ca673fec60d4d093668e4dff1a09861"
   },
   "source": [
    "# Loan Approval Prediction: \n",
    "### Random Forest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Importing Libraries ######################\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Count number of Categorical and Numerical Columns ######################\n",
    "train_df = train_df.drop(columns=['Loan_ID']) ## Dropping Loan ID\n",
    "categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Credit_History','Loan_Amount_Term']\n",
    "#categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area','Loan_Amount_Term']\n",
    "\n",
    "print(categorical_columns)\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Analyze values assigned to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(4,2,figsize=(12,15))\n",
    "for idx,cat_col in enumerate(categorical_columns):\n",
    "    row,col = idx//2,idx%2\n",
    "    sns.countplot(x=cat_col,data=train_df,hue='Loan_Status',ax=axes[row,col])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,3,figsize=(17,5))\n",
    "for idx,cat_col in enumerate(numerical_columns):\n",
    "    sns.boxplot(y=cat_col,data=train_df,x='Loan_Status',ax=axes[idx])\n",
    "\n",
    "print(train_df[numerical_columns].describe())\n",
    "plt.subplots_adjust(hspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Encoding categrical Features: ##########\n",
    "train_df_encoded = pd.get_dummies(train_df,drop_first=True)\n",
    "train_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Split Features and Target Varible ############\n",
    "dataset_without_loanStatus = train_df_encoded.drop(columns='Loan_Status_Y')\n",
    "loanStatus = train_df_encoded['Loan_Status_Y']\n",
    "\n",
    "################# Splitting into Train -Test Data #######\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_without_loanStatus_train,dataset_without_loanStatus_test,loanStatus_train,loanStatus_test = train_test_split(dataset_without_loanStatus, loanStatus, test_size=0.2,stratify =y,random_state =42)\n",
    "\n",
    "\n",
    "############### Handling/Imputing Missing values #############\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "imp_train = imp.fit(dataset_without_loanStatus_train)\n",
    "dataset_without_loanStatus_train = imp_train.transform(dataset_without_loanStatus_train)\n",
    "dataset_without_loanStatus_test_imp = imp_train.transform(dataset_without_loanStatus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,max_depth=3,min_samples_leaf = 10)\n",
    "rf_clf.fit(dataset_without_loanStatus_train, loanStatus_train)\n",
    "loanStatus_pred = rf_clf.predict(dataset_without_loanStatus_train)\n",
    "print(\"Train F1 Score \", f1_score(loanStatus_train, loanStatus_pred))\n",
    "print(\"Train Accuracy \", accuracy_score(loanStatus_train, loanStatus_pred))\n",
    "\n",
    "print(\"Validation Mean F1 Score: \",cross_val_score(rf_clf,dataset_without_loanStatus_train,loanStatus_train,cv=5,scoring='f1_macro').mean())\n",
    "print(\"Validation Mean Accuracy: \",cross_val_score(rf_clf,dataset_without_loanStatus_train,loanStatus_train,cv=5,scoring='accuracy').mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
